{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5190eb19-cf3b-40fd-9f6c-bcaab6ae1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b3aa9b-0310-4286-975b-34b41c1c2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/nethome/jbang36/eko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c4db3c-de97-447c-80f3-aaf324cd3565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11-29-2022 00:17:47 [info:049]INFO : meta data of the video /srv/data/jbang36/video_data/jackson/video.mp4 is (300000, 300, 300, 3)\n",
      "meta data of the video /srv/data/jbang36/video_data/jackson/video.mp4 is (300000, 300, 300, 3)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300000/300000 [00:58<00:00, 5124.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from eko_paper2022.motivation.main import *\n",
    "import time\n",
    "\n",
    "\n",
    "video_name = 'jackson'\n",
    "st = time.perf_counter()\n",
    "\n",
    "images = load_dataset(video_name)\n",
    "\n",
    "et = time.perf_counter() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f47ed05-a686-4529-a7b6-fc0a5fefb26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 300, 300, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceabf9f7-c793-4a68-adec-e2d0f78f7bb3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index initializing....\n",
      "number of training instances:  1\n",
      "mining complete!\n",
      "training complete!\n",
      "inferring complete!\n",
      "returning 1258 frames in 0.9538756310939789 seconds\n",
      "adfasdfasdfsaf 30000 0.5 15000\n",
      "total number of iframes:  1258\n",
      "total number of anchors selected in index construction:  15000\n",
      "final number that has been selected:  1259\n",
      "bucketing complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b1f349f6954a77a038c0e0bb8e82e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target DNN Invocations:   0%|          | 0/1259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28741/28741 [18:57<00:00, 25.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9b71bc7259463593f18fb8c923a6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Propagation:   0%|          | 0/300000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Derive Dataset Statistics\n",
    "category = 'car'\n",
    "\n",
    "from eko_paper2022.motivation.main import execute_ekoalt\n",
    "from eko_paper2022.experiments.main import *\n",
    "\n",
    "\n",
    "import time\n",
    "from eko_paper2022.experiments.main import execute_ekomab\n",
    "anchor_count = int(len(images) * 0.1)\n",
    "percentage = 0.5\n",
    "c_param = 2\n",
    "\n",
    "eko = execute_ekomab(images, video_name, category = category, nb_buckets = anchor_count, anchor_percentage = percentage, c_param = c_param)\n",
    "\n",
    "\n",
    "from eko_paper2022.experiments.main import *\n",
    "\n",
    "\n",
    "query = get_labels(eko)\n",
    "a = query.y_pred\n",
    "b = query.y_true\n",
    "gt_retrieval = []\n",
    "for bb in b:\n",
    "    gt_retrieval.append(float(bb))\n",
    "gt_retrieval = np.array(gt_retrieval)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd94d8ec-7992-428b-99b8-21bb6ec97144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04531"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(gt_retrieval) / len(gt_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22436bae-c6ed-4f46-b068-da84d3cc4e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ada851-dccb-4530-a564-25d37c67f001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c0a5d-83ca-4968-89b0-d4cd46a94840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fcdb4-9672-4863-85ba-33782c81ae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee3303b-2b7f-4966-ab10-7401e6a86f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /nethome/jbang36/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-3-2 torch 1.10.2 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37500/37500 [16:12<00:00, 38.56it/s]\n"
     ]
    }
   ],
   "source": [
    "### 1. load the dataset\n",
    "### 2. run the yolov5 detector\n",
    "### 3. save the result\n",
    "### 4. convert the data to tasti understandable format\n",
    "\n",
    "\n",
    "\n",
    "yolo_output = execute_yolo2(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b706971-9604-4319-9fff-208849a82757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd43de-69ed-483c-895d-cbc98152e613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f578c38-2960-4c72-8e24-7983e9d29f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db761d7a-e40f-44ae-8b99-e697219508f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 60 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa010ff-8275-4cf6-a55d-3a6154e9ff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['categories', 'annotations'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f361844a-b7d3-4bb9-99fa-0c6b03e9d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '/srv/data/jbang36/video_data/jackson/udf_annotations/yolov5.json'\n",
    "torch.save(yolo_output, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4df8b3-a1dd-4d5d-b81e-7e32f7bc0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we need to convert to tasti_labels.json\n",
    "\n",
    "#  /Users/KkaKkoong/Repos/eko/benchmarks/stanford/tasti/tasti/eko/utils/convert_labels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3350b104-2668-4367-a04a-06368e0fdec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping through Annotations: 300000it [00:00, 406796.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from benchmarks.stanford.tasti.tasti.eko.utils.convert_labels import convert\n",
    "load_dir = save_directory\n",
    "save_dir = '/srv/data/jbang36/video_data/jackson/tasti_labels.csv'\n",
    "convert(load_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05275d37-97a9-4a31-bf67-c3366f3ead8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### this should be query specific right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82af2d-9054-4c27-8646-dc396b441a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c7bb0-afb9-4b82-85b1-18390faa1f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d1bd8-1503-4196-b782-bb35910feb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490652d3-2692-457c-8afb-a2d0c4a2558a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
